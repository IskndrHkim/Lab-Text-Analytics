{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1a459e-b21e-499e-a6b0-d6e53ba917bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Requirement already satisfied: emoji in /home/d8db6fe4-06fa-44a2-a998-5bb20b593b23/.local/lib/python3.11/site-packages (2.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1b22d7-078f-4a29-a78d-bf80e8d55847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /usr/share/pip-wheels\n",
      "Requirement already satisfied: autocorrect in /home/d8db6fe4-06fa-44a2-a998-5bb20b593b23/.local/lib/python3.11/site-packages (2.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e72234e9-eae3-433f-8cff-aa3f761ffbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/d8db6fe4-06fa-44a2-a998-\n",
      "[nltk_data]     5bb20b593b23/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/d8db6fe4-06fa-44a2-a998-\n",
      "[nltk_data]     5bb20b593b23/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/d8db6fe4-06fa-44a2-a998-\n",
      "[nltk_data]     5bb20b593b23/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/d8db6fe4-06fa-44a2-a998-\n",
      "[nltk_data]     5bb20b593b23/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/d8db6fe4-06fa-44a2-a998-\n",
      "[nltk_data]     5bb20b593b23/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/d8db6fe4-06fa-44a2-a998-\n",
      "[nltk_data]     5bb20b593b23/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/d8db6fe4-06fa-44a2-a998-\n",
      "[nltk_data]     5bb20b593b23/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['Timestamp', 'Review'], dtype='object')\n",
      "                     Timestamp  \\\n",
      "0  2025/02/10 7:40:54 pm GMT+8   \n",
      "1  2025/02/10 7:41:00 pm GMT+8   \n",
      "2  2025/02/10 7:41:19 pm GMT+8   \n",
      "3  2025/02/10 7:46:40 pm GMT+8   \n",
      "4  2025/02/10 7:46:43 pm GMT+8   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                         Review  \n",
      "0                                                                                                                                                                                                                                                                                                          Im happy with uniten actually, even the people are W  \n",
      "1                                                                                                                                                                                                                                                                                      Iâm having a pretty good time here, happy to meet all of the W people.  \n",
      "2                                                                                                                                                                                                                                                                                                                   a very neutral place in terms of everything  \n",
      "3                                                                                                                                                                                                   I would say Uniten it's  a good university  but there is some issue need to be improved such as transportation,wifi networks and other facilities  as well.  \n",
      "4   UNITEN is well-regarded, particularly for its strong engineering, computer science, and business programs. It has a solid reputation in Malaysia, especially in energy-related fields. The negative part is the facilities such as the swimming pool are close since my first year till 3 year now and there are limited parking so it's make hard to find.  \n",
      "Null count: 0\n",
      "Example with URL: Series([], Name: Review, dtype: object)\n",
      "Example with HTML: Series([], Name: Review, dtype: object)\n",
      "Example with number: 4     UNITEN is well-regarded, particularly for its strong engineering, computer science, and business programs. It has a solid reputation in Malaysia, especially in energy-related fields. The negative part is the facilities such as the swimming pool are close since my first year till 3 year now and there are limited parking so it's make hard to find.\n",
      "Name: Review, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1841/204717309.py:102: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                         Review  \\\n",
      "0                                                                                                                                                                                                                                                                                                          Im happy with uniten actually, even the people are W   \n",
      "1                                                                                                                                                                                                                                                                                      Iâm having a pretty good time here, happy to meet all of the W people.   \n",
      "2                                                                                                                                                                                                                                                                                                                   a very neutral place in terms of everything   \n",
      "3                                                                                                                                                                                                   I would say Uniten it's  a good university  but there is some issue need to be improved such as transportation,wifi networks and other facilities  as well.   \n",
      "4   UNITEN is well-regarded, particularly for its strong engineering, computer science, and business programs. It has a solid reputation in Malaysia, especially in energy-related fields. The negative part is the facilities such as the swimming pool are close since my first year till 3 year now and there are limited parking so it's make hard to find.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                    processed  \n",
      "0                                                                                                                                                                                                                               [im, happy, unite, actually, even, people, w]  \n",
      "1                                                                                                                                                                                                                         [iâm, pretty, good, time, happy, meet, w, people]  \n",
      "2                                                                                                                                                                                                                                          [neutral, place, term, everything]  \n",
      "3                                                                                                                                                                   [would, say, united, good, university, issue, need, improve, transportationwifi, network, facility, well]  \n",
      "4  [united, wellregarded, particularly, strong, engineering, computer, science, business, program, solid, reputation, malaysia, especially, energyrelated, field, negative, part, facility, swim, pool, close, since, first, year, till, year, limit, park, make, hard, find]  \n",
      "Saved: Processed_UNITENReview.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "import string\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from autocorrect import Speller\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Download required NLTK resources (PDF) + punkt (needed by your environment)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')  # needed because your error said punkt not found\n",
    "\n",
    "# Initialize tools (PDF)\n",
    "spell = Speller(lang='en')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Slang dictionary (PDF)\n",
    "slang_dict = {\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\",\n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"ikr\": \"I know right\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"bff\": \"best friend forever\",\n",
    "    \"gg\": \"good game\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"rofl\": \"rolling on the floor laughing\"\n",
    "}\n",
    "\n",
    "# Contractions dictionary (PDF)\n",
    "contractions_dict = {\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"why's\": \"why is\"\n",
    "}\n",
    "\n",
    "# === Functions (PDF) ===\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+', '', text)\n",
    "\n",
    "def remove_html(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(text, replace='')\n",
    "\n",
    "def replace_slang(text):\n",
    "    escaped_slang_words = []\n",
    "    for word in slang_dict.keys():\n",
    "        escaped_word = re.escape(word)\n",
    "        escaped_slang_words.append(escaped_word)\n",
    "\n",
    "    slang_pattern = r'\\b(' + '|'.join(escaped_slang_words) + r')\\b'\n",
    "\n",
    "    def replace_match(match):\n",
    "        slang_word = match.group(0)\n",
    "        return slang_dict[slang_word.lower()]\n",
    "\n",
    "    replaced_text = re.sub(slang_pattern, replace_match, text, flags=re.IGNORECASE)\n",
    "    return replaced_text\n",
    "\n",
    "# Build regex for contractions (PDF)\n",
    "escaped_contractions = []\n",
    "for contraction in contractions_dict.keys():\n",
    "    escaped_contraction = re.escape(contraction)\n",
    "    escaped_contractions.append(escaped_contraction)\n",
    "\n",
    "joined_contractions = \"|\".join(escaped_contractions)\n",
    "contractions_pattern = r'\\b(' + joined_contractions + r')\\b'\n",
    "compiled_pattern = re.compile(contractions_pattern, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    def replace_match(match):\n",
    "        matched_word = match.group(0)\n",
    "        lower_matched_word = matched_word.lower()\n",
    "        expanded_form = contractions_dict[lower_matched_word]\n",
    "        return expanded_form\n",
    "\n",
    "    expanded_text = compiled_pattern.sub(replace_match, text)\n",
    "    return expanded_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "def correct_spelling(text):\n",
    "    return spell(text)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "def get_wordnet_pos(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "def tokenize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = remove_urls(text)\n",
    "    text = remove_html(text)\n",
    "    text = remove_emojis(text)\n",
    "    text = replace_slang(text)\n",
    "    text = replace_contractions(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = correct_spelling(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatize_text(text)\n",
    "    text = tokenize_text(text)\n",
    "    return text\n",
    "\n",
    "# === Exercise Step 1: identify issues (simple inspection) ===\n",
    "# Load UNITENReview.csv (if encoding problem, use latin1 like you did before)\n",
    "df = pd.read_csv(\"UNITENReview.csv\", encoding=\"latin1\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"Columns:\", df.columns)\n",
    "print(df.head())\n",
    "\n",
    "# These checks help you \"identify issues\" (URLs/HTML/emojis/numbers) in Review column\n",
    "review_col = \"Review\"  # as stated in exercise\n",
    "print(\"Null count:\", df[review_col].isna().sum())\n",
    "print(\"Example with URL:\", df[df[review_col].astype(str).str.contains(r'http|www', na=False)].head(1)[review_col])\n",
    "print(\"Example with HTML:\", df[df[review_col].astype(str).str.contains(r'<.*?>', na=False)].head(1)[review_col])\n",
    "print(\"Example with number:\", df[df[review_col].astype(str).str.contains(r'\\d', na=False)].head(1)[review_col])\n",
    "\n",
    "# === Exercise Step 2: apply preprocessing ===\n",
    "df[\"processed\"] = df[review_col].astype(str).apply(preprocess_text)\n",
    "\n",
    "# === Exercise Step 3: save to csv ===\n",
    "df.to_csv(\"Processed_UNITENReview.csv\", index=False)\n",
    "print(df[[review_col, \"processed\"]].head())\n",
    "print(\"Saved: Processed_UNITENReview.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
